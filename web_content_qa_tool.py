# -*- coding: utf-8 -*-
"""web_content_qa_tool.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MF58E4bLxJp_dkoxfquG282ee7r_9aVf
"""

import streamlit as st
import requests
from bs4 import BeautifulSoup

# Simple in-memory store for scraped content
if 'content_store' not in st.session_state:
    st.session_state.content_store = ''

st.title('Web Content Q&A Tool')

urls = st.text_area('Enter URLs (comma-separated)')
if st.button('Ingest Content'):
    st.session_state.content_store = ''
    url_list = urls.split(',')

    for url in url_list:
        try:
            response = requests.get(url.strip())
            soup = BeautifulSoup(response.content, 'html.parser')
            st.session_state.content_store += soup.get_text(separator=' ', strip=True) + ' '
        except Exception as e:
            st.error(f'Failed to fetch {url}: {str(e)}')
    st.success('Content ingested successfully')

question = st.text_input('Ask a question about the content')
if st.button('Get Answer'):
    if not st.session_state.content_store:
        st.warning('No content available. Please ingest URLs first.')
    else:
        # Simple keyword-based search (can be improved with NLP models)
        if question.lower() in st.session_state.content_store.lower():
            start = st.session_state.content_store.lower().find(question.lower())
            end = min(start + 300, len(st.session_state.content_store))
            st.write(st.session_state.content_store[start:end])
        else:
            st.write('No relevant information found.')

